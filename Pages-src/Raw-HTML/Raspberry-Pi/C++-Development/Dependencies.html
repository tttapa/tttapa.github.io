<!--
@title: Cross-Compiling the Dependencies
@sequence: 20
@tableofcontents: true
@shownextupprevpage: true
@author: Pieter P
@keywords: cross-compile,raspberry,raspberry pi,build,compile,from source,
           source,Zlib,OpenSSL,FFI,Bzip2,GNU ncurses,GNU readline,GNU dbm,
           SQLite,UUID,Python 3.7.4,ZBar,Raspberry Pi Userland,VideoCore,
           FFmpeg,OpenCV,NumPy
@description: Using the cross-compilation toolchain to build the libraries you
              need for your project, as well as their dependencies.
-->
<html>

<h3>Sysroot and Staging Area</h3>

<p>
    Because we don't have access to the actual root file system of the Raspberry Pi, with all of its system files and
    libraries, the toolchain uses a so-called <b>sysroot</b> folder. It contains the necessary system libraries, such as
    glibc and the C++ standard library. It's also the folder where the configure scripts of other libraries will
    look for the necessary libraries and headers. The sysroot is generated by crosstool-NG, and it is
    part of the cross-compilation toolchain. It is not used when deploying your software to the Pi.
</p>
<p>
    The sysroot of the toolchain is read-only, to keep it clean for future projects, so we'll make a copy of the sysroot
    for this build, and make the copy writable.<br>
    This copy will be used as the sysroot for all compilations, and all cross-compiled libraries will be installed to
    this folder. We have to do this, because the configure scripts (Autoconf's configure script, CMake, etc.) of other
    libraries or programs will search for their dependencies in the sysroot. If these dependencies are not found,
    configuration or compilation will fail, or parts of the program/library may be implicitly disabled.
</p>
<p>
    Apart from the sysroot, we also need a folder containing the files we want to install to the Pi. It should contain
    the binaries we cross-compiled (such as <code>/usr/local/bin/python3</code>) and the necessary libraries (such as
    <code>/usr/local/lib/libpython3.so</code>).
    It doesn't contain the system libraries, because the Pi already has these installed. This folder is called the
    <b>staging area</b>.
</p>
<p>
    Having both a sysroot and a staging area means we have to install every library twice, once in
    each of the two folders.<br>
    The sysroot is later used when compiling our example program, the staging area will be copied to the Pi for running
    the example program.
</p>

<h3>Cross-Compiling the dependencies using the provided shell scripts</h3>

<p>
    To build all dependencies, you can use the shell script provided in the
    <code>toolchain</code> folder:
</p>
<pre class="console">
<code>./docker-arm-cross-build-scripts/build.sh &lt;board&gt; --export</code>
</pre>
<p>
    Replace <code>&lt;board&gt;</code> with your specific board.
    Run <code>./docker-arm-cross-build-scripts/build.sh</code> without arguments
    to see the possible options.
</p>

<!-- <p>
    Where <code>&lt;board&gt;</code> is one of the following:
</p>
<ul>
    <li><code>rpi</code>: Raspberry Pi 1 or Zero, dependencies only</li>
    <li><code>rpi-dev</code>: Raspberry Pi 1 or Zero, dependencies and development tools</li>
    <li><code>rpi3-armv8</code>: Raspberry Pi 3, 32-bit, dependencies only</li>
    <li><code>rpi3-armv8-dev</code>: Raspberry Pi 3, 32-bit, dependencies and development tools</li>
    <li><code>rpi3-aarch64</code>: Raspberry Pi 3, 64-bit, dependencies only</li>
    <li><code>rpi3-aarch64-dev</code>: Raspberry Pi 3, 64-bit, dependencies and development tools</li>
</ul> -->
<p>
    The dependencies that are cross-compiled are:
</p>
<ul>
    <li><strong>Zlib</strong>: compression library (OpenSSL and Python dependency)</li>
    <li><strong>OpenSSL</strong>: cryptography library (Python dependency)</li>
    <li><strong>FFI</strong>: foreign function interface (Python dependency, used to call C functions using ctypes)
    </li>
    <li><strong>Bzip2</strong>: compression library (Python dependency)</li>
    <li><strong>GNU ncurses</strong>: library for text-based user interfaces (Python dependency, used for the
        console)</li>
    <li><strong>GNU readline</strong>: library for line-editing and history (Python dependency, used for the
        console)</li>
    <li><strong>GNU dbm</strong>: library for key-value data (Python dependency)</li>
    <li><strong>SQLite</strong>: library for embedded databases (Python dependency)</li>
    <li><strong>UUID</strong>: library for unique identifiers (Python dependency)</li>
    <li><strong>libX11</strong>: X11 protocol client library (Tk dependency)</li>
    <li><strong>Tcl/Tk</strong>: graphical user interface toolkit (Python/Tkinter dependency)</li>
    <li><strong>Python 3.10.4</strong>: Python interpreter and libraries</li>
    <li><strong>ZBar</strong>: Bar and QR code decoding library</li>
    <li><strong>Raspberry Pi Userland</strong>: VideoCore GPU drivers</li>
    <li><strong>VPX</strong>: VP8/VP9 codec SDK</li>
    <li><strong>x264</strong>: H.264/MPEG-4 AVC encoder</li>
    <li><strong>Xvid</strong>: MPEG-4 video codec</li>
    <li><strong>FFmpeg</strong>: library to record, convert and stream audio and video</li>
    <li><strong>OpenBLAS</strong>: linear algebra library (NumPy dependency)</li>
    <li><strong>NumPy</strong>: multi-dimensional array container for Python (OpenCV dependency)</li>
    <li><strong>SciPy</strong>: Python module for mathematics, science, and engineering</li>
    <li><strong>OpenCV</strong>: computer vision library and Python module</li>
</ul>
</p>
<p>
    The development tools that are cross-compiled are:
</p>
<ul>
    <!-- <li><strong>GCC 9.2.0</strong>: C, C++ and Fortran compilers (see native toolchain on the previous page)</li> -->
    <li><strong>GNU Make</strong>: build automation tool</li>
    <li><strong>Ninja</strong>: faster, more light-weight build tool</li>
    <li><strong>CMake</strong>: build system</li>
    <li><strong>Distcc</strong>: distributed compiler wrapper (uses your computer to speed up compilation on the
        RPi)</li>
    <li><strong>CCache</strong>: compiler cache</li>
    <li><strong>cURL</strong>: tool and library for transferring data over the network (Git dependency)</li>
    <li><strong>Git</strong>: version control system</li>
</ul>
<p>
    Note that building all of these dependencies will take a long time.
</p>

<h3>Pulling the cross-compiled dependencies from Docker Hub</h3>

<p>
    If you don't want to change anything to the build process, or if you have a
    slow computer, you can just pull the Docker images that I compiled from
    Docker Hub:
</p>

<pre class="console">
<code>./docker-arm-cross-build-scripts/build.sh &lt;board&gt; --pull --export</code>
</pre>
<p>
    Replace <code>&lt;board&gt;</code> with your specific board.
    Run <code>./docker-arm-cross-build-scripts/build.sh</code> without arguments
    to see the possible options.
</p>

<h2>Detailed information about cross-compilation of libraries</h2>

<p>
    You don't need to read or understand the sections below if you just want to use the provided libraries.<br>
    On the other hand, if you're interested in how cross-compilation works, or if you want to cross-compile additional
    libraries, you'll find the necessary details below.
</p>

<h3>Cross-Compiling the dependencies</h3>

<p>
    If you want to write a program that uses the OpenCV library, for example,
    you have to cross-compile OpenCV and install it to
    the Raspberry Pi. But in order to cross-compile OpenCV itself, you need to cross-compile all of its dependencies as
    well. This can keep going for a while, and you may end up with a pretty large hierarchy of dependencies.
</p>
<p class="gray-block-quote">
    <b>Note</b>: For this reason, it is often
    better to use a package manager like APT instead of building all dependencies from source.
    To learn how to use APT when cross-compiling, 
    see the guide <a href="../C++-Development-RPiOS/index.html">Ubuntu to Raspberry Pi OS Cross C++ Development</a>.
</p>

<p>
    The main Dockerfile discussed below sets up the build environment, and then runs the installation scripts in the
    <a
        href="https://github.com/tttapa/RPi-Cpp-Toolchain/tree/master/toolchain/docker/merged/cross-build/install-scripts"><code>toolchain/docker/merged/cross-build/install-scripts</code></a>
    folder. If you want to omit some of the libraries, you can comment them out in the Dockerfile, but keep in mind that
    it might break other libraries that depend on it.<br>
    Some libraries such as SciPy need to be patched to get them to cross-compile correctly. These patches can be found
    in the <a
        href="https://github.com/tttapa/RPi-Cpp-Toolchain/tree/master/toolchain/docker/merged/cross-build/patches"><code>patches</code></a>
    folder.
</p>
<p>
    For most packages, the build procedure is very simple:
<ol>
    <li>Download</li>
    <li>Extract</li>
    <li>Run the <code>configure</code> script with the right options</li>
    <li><code>make</code></li>
    <li><code>make install</code></li>
</ol>
An example is given below.
</p>

<h4>Board-specific configuration</h4>

<p>
    The configuration for the different Raspberry Pi models is passed to the
    build scripts using environment variables. For example:
</p>

@codesnippet{
"name": "aarch64-rpi3-linux-gnu.env",
"file": "${HOME}/GitHub/RPi-Cpp-Toolchain/docker-arm-cross-build-scripts/env/aarch64-rpi3-linux-gnu.env",
"lexer": "bash"
}

<h4>Compiling a library for the Docker container</h4>

<p>
    In the first section of the main Dockerfile, some packages are built for both the build machine (the Docker
    container) and for the host machine (the Raspberry Pi), because we need to build Python for both machines in order
    to cross-compile the OpenCV and NumPy modules later on.
</p>
<p>
    Since these are just basic native installations, you can simply follow the documentation for the library in
    question.
    All of the necessary tools should be installed in the <a href="#base-image">base image</a>.
</p>

<h4>Cross-Compiling a library for the Raspberry Pi</h4>

<p>
    Cross-compiling is a bit harder, because most libraries don't provide good documentation about the cross-compilation
    process. However, once you understand the concepts, you'll be able to apply them to almost any library, and with
    the necessary tweaks, you should be able to get it working.
</p>
<p>
    We'll have a look at a typical example, compiling <code>libffi</code>, a foreign function interface library
    that is used by Python's <code>ctypes</code> module.
</p>

@codesnippet{
"name": "libffi.sh",
"file":
"${HOME}/GitHub/RPi-Cpp-Toolchain/docker-arm-cross-build-scripts/cross-build/install-scripts/libffi.sh"
}

<h5>Downloading and extracting</h5>
<p>
    The first couple of lines are really straightforward, they simply download the library from GitHub, extract it, and
    enter the library's directory.
</p>
<h5>pkg-config</h5>
<p>
    Most configure scripts use <code>pkg-config</code>, a simple tool to find libraries that are installed on the
    system, and to determine what flags are necessary to use them. We want <code>pkg-config</code> to find the libraries
    in the Raspberry Pi sysroot, not in the root folder of the Docker container, because these libraries are for the
    wrong architecture.<br>
    The <code>cross-pkg-config</code> script that is sourced on line 16 sets some environment variables in order to tell
    <code>pkg-config</code> to only search for libraries in the Raspberry Pi sysroot.
</p>
<h5>Autoconf</h5>
<p>
    Many older libraries use GNU Autoconf to configure the project before building. Autoconf generates the
    <code>configure</code> script, and then the <code>configure</code> script generates the makefiles that are used to
    actually compile and install the software. When downloading a library directly from GitHub (or some other source
    control host), it usually doesn't include the <code>configure</code>. In that case, you have to run Autoconf before
    configuring. If you download a released tarball from the
    project's website, this isn't usually required.
</p>
<h5>Configure</h5>
<p>
    The <code>configure</code> script checks the system configuration, looks for libraries, and generates the
    makefiles.<br>
    We have to specify that we are cross-compiling by providing the <code>--host</code> flag. As mentioned before, the
    <code>--prefix</code> option specifies the directory where the library will be installed on the Raspberry Pi.
    Software that isn't managed by the system's package manager should be installed to <code>/usr/local</code>.<br>
    You can add your own compiler flags if you want, using the <code>CFLAGS</code>, <code>CXXFLAGS</code> and
    <code>LDFLAGS</code> variables. Finally, we tell the configure script to use our custom sysroot, instead of the
    toolchain's default. Some configure scripts don't support the <code>--with-sysroot</code> flag. In that case, you
    can add the <code>--sysroot="..."</code> option to the <code>CFLAGS</code>, <code>CXXFLAGS</code> and
    <code>LDFLAGS</code> environment variables.
</p>
<p>
    To find out what options you can pass to the <code>configure</code> script, you can run
    <code>./configure --help</code>.
    Usually, a library also comes with some documentation about these options, for example in the <code>README</code> or
    <code>INSTALL</code> documents.
</p>
<h5>Compilation</h5>
<p>
    This is probably the easiest step, you can simply type <code>make</code> to compile everyting. To speed up the
    build, <code>make</code>'s <code>-j</code> (<code>--jobs</code>) option is used to compile multiple source files in
    parallel. <code>nproc</code> returns the number of available processing units (cores/threads) in your computer.
    It's multiplied by two, and then passed to <code>make</code>.
</p>
<h5>Installation</h5>
<p>
    Once everything has been compiled, we'll install everything in the sysroot and in the staging area. When running
    <code>make install DESTDIR="..."</code>, the files will be installed <code>DESTDIR/PREFIX</code>, that is, the
    <code>DESTDIR</code> variable passed to <code>make</code> and the <code>--prefix</code> specified during
    configuration will be concatenated. The prefix matters both during compilation/installation and at runtime,
    the <code>DESTDIR</code> just determines where they are installed, and is not used at runtime.<br>
    The <code>DESTDIR</code> variable also makes it very easy to install the package at two locations, the sysroot
    and the staging area without building the package twice.
</p>
<h5>Cleanup</h5>
<p>
    Finally, we just delete the entire build directory to keep the size of the Docker image low. When debugging, you
    might want to keep the build directory, so you can start a docker container and try out some things in an
    interactive shell.
</p>

</html>
<!--
@title: Cross-Compiling the Dependencies
@sequence: 20
@tableofcontents: true
@shownextupprevpage: true
@author: Pieter P
@keywords: cross-compile,raspberry,raspberry pi,build,compile,from source,
           source,Zlib,OpenSSL,FFI,Bzip2,GNU ncurses,GNU readline,GNU dbm,
           SQLite,UUID,Python 3.7.4,ZBar,Raspberry Pi Userland,VideoCore,
           FFmpeg,OpenCV,NumPy
@description: Using the cross-compilation toolchain to build the libraries you
              need for your project, as well as their dependencies.
-->
<html>

<h3>Sysroot and Staging Area</h3>

<p>
    Because we don't have access to the actual root directory of the Raspberry Pi, with all of its system files and
    libraries, the toolchain uses a so-called <b>sysroot</b> folder. It contains the necessary system libraries, such as
    glibc and the C++ standard library. It's also the folder where the configure scripts of other libraries will
    look for the necessary libraries and headers. The sysroot is generated by Crosstool-NG, and it is
    part of the cross-compilation toolchain. It is not used for deploying your software to the Pi.
</p>
<p>
    The sysroot of the toolchain is read-only, to keep it clean for future projects, so we'll make a copy of the sysroot
    for this build, and make it writable.<br>
    This copy will be used as the sysroot for all compilations, and all cross-compiled libraries will be installed to
    this folder. We have to do this, because the configure scripts (Autoconf's configure script, CMake, etc.) of other
    libraries or programs will search for their dependencies in the sysroot. If these dependencies are not found,
    configuration or compilation will fail, or parts of the program/library may be implicitly disabled.
</p>
<p>
    Apart from the sysroot, we also need a folder containing the files we want to install to the Pi. It should contain
    the binaries we cross-compiled (such as <code>/usr/local/bin/python3.8</code>) and the necessary libraries (such as
    <code>/usr/local/lib/libpython3.8.so</code>).
    It doesn't contain the system libraries, because the Pi already has these installed. This folder is called the
    <b>staging area</b>.
</p>
<p>
    Having both a sysroot and a staging area means we have to install every library twice, once in
    each of the two folders.<br>
    The sysroot is later used when compiling our program, the staging area will be copied to the Pi for running our
    program.
</p>

<h3>Cross-Compiling the dependencies using the provided shell scripts</h3>

<p>
    If you just want to build all dependencies and libraries, without you can use the shell scripts provided in the
    <code>toolchain</code> folder:
</p>
<pre class="console">
<code>./toolchain/build-and-export.sh &lt;board&gt;</code>
</pre>

<p>
    Where <code>&lt;board&gt;</code> is one of the following:
    <ul>
        <li><code>rpi</code>: Raspberry Pi 1 or Zero, dependencies only</li>
        <li><code>rpi-dev</code>: Raspberry Pi 1 or Zero, dependencies and development tools</li>
        <li><code>rpi3-armv8</code>: Raspberry Pi 3, 32-bit, dependencies only</li>
        <li><code>rpi3-armv8-dev</code>: Raspberry Pi 3, 32-bit, dependencies and development tools</li>
        <li><code>rpi3-aarch64</code>: Raspberry Pi 3, 64-bit, dependencies only</li>
        <li><code>rpi3-aarch64-dev</code>: Raspberry Pi 3, 64-bit, dependencies and development tools</li>
    </ul>
</p>
<p>
    The dependencies that are cross-compiled are:
    <ul>
        <li><strong>Zlib</strong>: compression library (OpenSSL and Python dependency)</li>
        <li><strong>OpenSSL</strong>: cryptography library (Python dependency)</li>
        <li><strong>FFI</strong>: foreign function interface (Python dependency, used to call C functions using ctypes)
        </li>
        <li><strong>Bzip2</strong>: compression library (Python dependency)</li>
        <li><strong>GNU ncurses</strong>: library for text-based user interfaces (Python dependency, used for the
            console)</li>
        <li><strong>GNU readline</strong>: library for line-editing and history (Python dependency, used for the
            console)</li>
        <li><strong>GNU dbm</strong>: library for key-value data (Python dependency)</li>
        <li><strong>SQLite</strong>: library for embedded databases (Python dependency)</li>
        <li><strong>UUID</strong>: library for unique identifiers (Python dependency)</li>
        <li><strong>Python 3.8.1</strong>: Python interpreter and libraries</li>
        <li><strong>ZBar</strong>: Bar and QR code decoding library</li>
        <li><strong>Raspberry Pi Userland</strong>: VideoCore GPU drivers</li>
        <li><strong>VPX</strong>: VP8/VP9 codec SDK</li>
        <li><strong>x264</strong>: H.264/MPEG-4 AVC encoder</li>
        <li><strong>Xvid</strong>: MPEG-4 video codec</li>
        <li><strong>FFmpeg</strong>: library to record, convert and stream audio and video</li>
        <li><strong>OpenBLAS</strong>: linear algebra library (NumPy dependency)</li>
        <li><strong>NumPy</strong>: multi-dimensional array container for Python (OpenCV dependency)</li>
        <li><strong>SciPy</strong>: Python module for mathematics, science, and engineering</li>
        <li><strong>OpenCV 4.2.0</strong>: computer vision library and Python module</li>
    </ul>
</p>
<p>
    The development tools that are cross-compiled are:
    <ul>
        <li><strong>GCC 9.2.0</strong>: C, C++ and Fortran compilers (see native toolchain on the previous page)</li>
        <li><strong>GNU Make</strong>: build automation tool</li>
        <li><strong>CMake</strong>: build system</li>
        <li><strong>Distcc</strong>: distributed compiler wrapper (uses your computer to speed up compilation on the
            RPi)</li>
        <li><strong>CCache</strong>: compiler cache</li>
        <li><strong>cURL</strong>: tool and library for transferring data over the network (Git dependency)</li>
        <li><strong>Git</strong>: version control system</li>
    </ul>
</p>

<h2>Detailed information about cross-compilation of libraries</h2>

<h3>Base Image</h3>

<p>
    Before building the dependencies, I created a base image with Ubuntu and the
    necessary tools installed. I also created a non-root user.
</p>

@codesnippet{
"name": "Dockerfile",
"file": "${HOME}/GitHub/RPi-Cpp-Toolchain/toolchain/docker/base-ubuntu/Dockerfile"
}

<h3>Cross-Compiling the dependencies</h3>

<p>
    If you want to write a program that uses the OpenCV library, you have to cross-compile OpenCV and install it to
    the Raspberry Pi. But in order to cross-compile OpenCV itself, you need to cross-compile all of its dependencies as
    well. This can keep going for a while, and you may end up with a pretty large hierarchy of dependencies.
</p>
<p>
    The main Dockerfile discussed below sets up the build environment, and then runs the installation scripts in the
    <a
        href="https://github.com/tttapa/RPi-Cpp-Toolchain/tree/master/toolchain/docker/rpi3/aarch64/aarch64-cross-build/install-scripts"><code>toolchain/docker/rpi3/aarch64/aarch64-cross-build/install-scripts</code></a>
    folder. If you want to omit some of the libraries, you can comment them out in the Dockerfile, but keep in mind that
    it might break other libraries that depend on it.<br>
    Some libraries such as SciPy need to be patched to get them to cross-compile correctly. These patches can be found
    in the <a
        href="https://github.com/tttapa/RPi-Cpp-Toolchain/tree/master/toolchain/docker/rpi3/aarch64/aarch64-cross-build/patches"><code>patches</code></a>
    folder.
</p>
<p>
    For most packages, the build procedure is very simple:
    <ol>
        <li>Download</li>
        <li>Extract</li>
        <li>Run the <code>configure</code> script with the right options</li>
        <li><code>make</code></li>
        <li><code>make install</code></li>
    </ol>
    An example is given below.
</p>

<h4>Preparing the Sysroot and Staging Area</h4>

@codesnippet{
"name": "Dockerfile",
"file": "${HOME}/GitHub/RPi-Cpp-Toolchain/toolchain/docker/rpi3/aarch64/aarch64-cross-build/Dockerfile",
"endline": 26
}

<h4>Compiling a library for the Docker container</h4>

<p>
    In the first section of the main Dockerfile, most packages are built for both the build machine (the Docker
    container) and for the host machine (the Raspberry Pi), because we need to build Python for both machines in order
    to cross-compile the OpenCV and NumPy modules later on.
</p>
<p>
    Since these are just basic native installations, you can simply follow the documentation for the library in
    question.
    All of the necessary tools should be installed in the <a href="#base-image">base image</a>.
</p>

<h4>Cross-Compiling a library for the Raspberry Pi</h4>

<p>
    Cross-compiling is a bit harder, because most libraries don't provide good documentation about cross-compilation.
    However, once you understand the concepts, you'll be able to apply them to almost any library.
</p>
<p>
    We'll have a look at a typical example, compiling <code>libffi</code>, a foreign function interface library
    that is used by Python's <code>ctypes</code> module.
</p>

@codesnippet{
"name": "libffi.sh",
"file":
"${HOME}/GitHub/RPi-Cpp-Toolchain/toolchain/docker/rpi3/aarch64/aarch64-cross-build/install-scripts/libffi.sh"
}

<h5>Downloading and extracting</h5>
<p>
    The first couple of lines are really straightforward, they simply download the library from GitHub, extract it, and
    enter the library's directory.
</p>
<h5>pkg-config</h5>
<p>
    Most configure scripts use <code>pkg-config</code>, a simple tool to find libraries that are installed on the
    system, and to determine what flags are necessary to use them. We want <code>pkg-config</code> to find the libraries
    in the Raspberry Pi sysroot, not in the root folder of the Docker container, because these libraries are for the
    wrong architecture.<br>
    The <code>cross-pkg-config</code> script that is sourced on line 16 sets some environment variables in order to tell
    <code>pkg-config</code> to only search for libraries in the Raspberry Pi sysroot.
</p>
<h5>Autoconf</h5>
<p>
    Many older libraries use GNU Autoconf to configure the project before building. Autoconf generates the
    <code>configure</code> script, and then the <code>configure</code> script generates the makefiles that are used to
    actually compile and install the software. When downloading a library directly from GitHub (or other source control
    host), you usually have to run Autoconf before configuring. If you download a released tarball from the project's
    website, this isn't usually required.
</p>
<h5>Configure</h5>
<p>
    The <code>configure</code> script checks the system configuration, looks for libraries, and generates the
    makefiles.<br>
    We have to specify that we are cross-compiling by providing the <code>--host</code> flag. As mentioned before, the
    <code>--prefix</code> option specifies the directory where the library will be installed on the Raspberry Pi.
    Software that isn't managed by the system's package manager should be installed to <code>/usr/local</code>.<br>
    You can add your own compiler flags if you want, using the <code>CFLAGS</code>, <code>CXXFLAGS</code> and
    <code>LDFLAGS</code> variables. Finally, we tell the configure script to use our custom sysroot, instead of the
    toolchain's default. Some configure scripts don't support this. In that case, you can add the
    <code>--sysroot="..."</code> option to the <code>CFLAGS</code>, <code>CXXFLAGS</code> and <code>LDFLAGS</code>
    variables.
</p>
<p>
    To find out what options you can pass to the <code>configure</code> script, you can run
    <code>./configure --help</code>.
    Usually, a library also comes with some documentation about these options, for example in the <code>README</code> or
    <code>INSTALL</code> documents.
</p>
<h5>Compilation</h5>
<p>
    This is probably the easiest step, you can simply type <code>make</code> to compile everyting. To speed up the
    build, <code>make</code>'s <code>-j</code> (<code>--jobs</code>) option is used to compile multiple source files in
    parallel. <code>nproc</code> returns the number of available processing units (cores/threads) in your computer.
    It's multiplied by two, and then passed to <code>make</code>.
</p>
<h5>Installation</h5>
<p>
    Once everything has been compiled, we'll install everything in the sysroot and in the staging area. When running
    <code>make install DESTDIR="..."</code>, the files will be installed <code>DESTDIR/PREFIX</code>, that is, the
    <code>DESTDIR</code> variable passed to <code>make</code> and the <code>--prefix</code> specified during
    configuration will be concatenated. The prefix matters both during compilation/installation and at runtime,
    the <code>DESTDIR</code> just determines where they are installed, and is not used at runtime.<br>
    The <code>DESTDIR</code> variable also makes it very easy to install the package at two locations, the sysroot
    and the staging area without building the package twice.
</p>
<h5>Cleanup</h5>
<p>
    Finally, we just delete the entire build directory to keep the size of the Docker image low.
</p>

</html>
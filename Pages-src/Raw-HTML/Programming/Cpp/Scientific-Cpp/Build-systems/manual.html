<!--
@title: Manual compilation
@sequence: 3000
@author: Pieter P
@tableofcontents: true
@shownextupprevpage: true
@keywords:
@description: Manually invoking the compiler to gain an understanding and
              appreciation of the specific tasks a build system performs for
              you.
@article-class: book-section
-->

<html>
<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>

<p>
    In this section, we'll manually invoke the compiler to build a very simple
    “Hello, World”-style program that consists of multiple source files.
    The goal is to illustrate how building software works under the hood, and
    motivate the use of a build system or build system generator to automate
    this tedious task.
</p>

<h2>Example project</h2>

<p>
    Consider a small project that consists of two libraries and a main program.
</p>
<ul>
    <li>The first library (A) defines the <code>say_hello()</code> function. It
        uses the <a href="https://github.com/fmtlib/fmt"><code>{fmt}</code></a>
        library to print a greeting to the console.</li>
    <li>The second library (B) uses the <code>say_hello()</code> function from
        library A to implement the <code>greet_many()</code> function that
        greets multiple people.</li>
    <li>Finally, the main program creates an array with names of people to greet,
        and calls library B’s <code>greet_many()</code> function.</li>
</ul>

<p>
    The project layout could look something like this:
</p>

<pre class="code"><code>├── liba</code>
<code>│   ├── a.cpp</code>
<code>│   └── a.hpp</code>
<code>├── libb</code>
<code>│   ├── b.cpp</code>
<code>│   └── b.hpp</code>
<code>└── main.cpp</code></pre>

<style>
    div.twocolumns {
        display: flex;
        column-gap: 1.6em;
        flex-wrap: wrap;
    }

    div.twocolumns>div {
        flex: 1 1 40%;
    }
</style>

<h3>Source code</h3>

<p>
    The source code listed below is not too important in and of itself, what
    matters are the dependencies between the different source files.
</p>

<div class="twocolumns">
    <div>
        @codesnippet{ "file": "resources/liba/a.hpp",
        "name": "Header A (liba/a.hpp)" }
    </div>
    <div>
        @codesnippet{ "file": "resources/liba/a.cpp",
        "name": "Implementation A (liba/a.cpp)" }
    </div>
    <div>@codesnippet{ "file": "resources/libb/b.hpp",
        "name": "Header B (libb/b.hpp)" }
    </div>
    <div>@codesnippet{ "file": "resources/libb/b.cpp",
        "name": "Implementation B (libb/b.cpp)" }
    </div>
    <div>@codesnippet{ "file": "resources/main.cpp",
        "name": "Main program (main.cpp)" }
    </div>
</div>

<h2>Header files and implementation files</h2>

<p>
    Most C++ source files fall into one of two categories: header files and implementation files.
    Implementation files (usually with extension <code>.cpp</code>, <code>.cc</code> or <code>.cxx</code>) are files
    that contain function or variable definitions, and are compiled into executable code.
    Header files (usually with extension <code>.hpp</code>, <code>.h</code> or <code>.hxx</code>) contain declarations,
    function prototypes and class definitions. They are not compiled in isolation, but are intended to be included in
    implementation files or in other header files.<br>
    Broadly speaking, the API of a library (i.e. the declarations that are needed to <i>use</i> the library) is
    declared in header files.
    The actual executable code (i.e. the definitions of the functions provided by the library)
    exists across multiple implementation files.
</p>

<h2>The compilation process</h2>

<p>
    The compiler performs different intermediate steps as part of the build
    process:
</p>
<ol>
    <li><b>Pre-processing</b>:
        including header files by expanding <code>#include</code> directives, performing macro substitution, handling
        <code>#if</code> directives, etc.
    </li>
    <li><b>Compilation</b>:
        parsing and interpreting the pre-processed source code, and composing the corresponding intermediate
        representation. Along the way, syntactical and semantic errors are reported.</li>
    <li><b>Optimization</b>:
        iteratively rewriting the intermediate representation to improve performance and/or memory usage, without
        changing the observable behavior of the code.</li>
    <li><b>Code generation and assembly</b>:
        converting the intermediate representation into executable machine code. </li>
    <li><b>Linking</b>:
        combining the machine code for different files and libraries into a single binary.</li>
</ol>

<h3>Pre-processing</h3>

<p>
    The pre-processor's duty is to handle all pre-processor directives, like <code>#include</code>,
    <code>#if/#elif/#else/#endif</code>, <code>#define</code>, and it performs simple text-based macro expansion. It
    also strips the comments from the source code.
</p>
<p>
    It is important to note that the preprocessor actually pastes the contents of header files into the source files
    that include them. This is done using relatively simple text substitution of the <code>#include</code> directive,
    with some bookkeeping to be able to recover the original file names and line numbers. An example of a pre-processed
    version of the file <code>b.cpp</code> from above is listed below. This is the kind of code that is actually handed
    to the compiler.
</p>

@codesnippet{ "file": "resources/libb/b.i",
"name": "Pre-processed source code of implementation B (libb/b.i)" }

<p>
    The directives starting with a <code>#</code> refer back to the original location of the source code.
    You can see how the headers <code>a.hpp</code> and <code>b.hpp</code> have been inlined and combined with the other
    contents of <code>b.cpp</code>. This inlining is done recursively: all <code>#include</code> directives are
    expanded, including standard library headers (which have been omitted for clarity). The preprocessor also removes
    all comments from the code, the comments in the snippet above were added manually to point out the different parts.
</p>

<h3>Compilation, optimization and code generation</h3>

<p>
    Modern compilers are among the most sophisticated pieces of software out there, and a detailed description falls
    beyond the scope of this document.
    <span style="color: red">TODO: add references</span>
</p>

<h3>Linking</h3>

<p>
    <span style="color: red">TODO: explain object files</span>
</p>

<h2>Building the example project</h2>

<p>
    To build the main executable for the example project above, some of the steps are combined, and the two main steps
    in the build process are:
</p>
<ol class="circled">
    <li>Pre-process and compile all implementation files into object files (covers pre-processing, compiling,
        optimizing, assembling).</li>
    <li>Link all object files and external libraries into an executable.</li>
</ol>
<p>
    Using GCC, this can be done as follows:
</p>

@codesnippet{ "file": "resources/build.sh",
"name": "Build commands" }

<ol class="circled">
    <li>
        The <code>-c</code> option causes GCC to preprocess and <u><b>c</b></u>ompile the
        given file, writing the resulting object file to the <u><b>o</b></u>utput file
        specified using the <code>-o</code> flag.
        When preprocessing <code>a.cpp</code>, GCC needs to locate the header file
        <code>a.hpp</code>, so the directory containing this file is added to the
        <u><b>i</b></u>nclude path using the <code>-I</code> flag. Similarly, the
        preprocessing of <code>b.cpp</code> requires both <code>liba</code> and
        <code>libb</code> to be added to the search path, and <code>main.cpp</code>
        needs <code>libb</code>.
        We assume that the <code>{fmt}</code> library is installed in
        <code>/usr/include</code> or some other location that is already in GCC’s
        default search path. If this were not the case, we would add another
        <code>-I</code> or <code>-isystem</code> flag to inform the preprocessor of
        its location.
    </li>
    <li>
        The invocation of GCC without the <code>-c</code> option links the three
        object files together into an executable. Since <code>a.cpp</code> makes
        use of the <code>{fmt}</code> library, we need to <u><b>l</b></u>ink to this
        library as well, using the <code>-l</code> flag. Here we again assume that
        the <code>libfmt.so</code> library is in a standard location, otherwise we
        would need to use the <code>-L</code> flag to add its location to the
        <u><b>l</b></u>ibrary search path.
    </li>
</ol>
<p>
    The dependencies between the different files involved in the build process
    are visualized in @ref{"ref": "graph-compile-project"}.
</p>

@image{ "file": "images/project.mmd",
"label": "graph-compile-project",
"caption": "Dependencies between files used during the build process." }

<h2>Limitations of manual compilation</h2>

<p>
    Manually invoking the compiler like this (with or without a shell script)
    has some serious downsides and challenges, including:
</p>
<ol>
    <li><b>Repetitiveness and boilerplate</b>: Building a C++ project involves many similar
        calls to the compiler. Although the number of commands to write can be somewhat reduced using wildcards or Bash
        scripting, we need a more structural solution that is easy to maintain when files are added or when the
        layout of the project changes.
    </li>
    <li><b>Propagation of compiler flags</b>: Some compiler options (such as preprocessor macros, C++ standard versions
        and include paths) need to be propagated from a library to its dependents. For example, library B uses library
        A, so the location of <code>a.hpp</code> needs to be added to the search paths when compiling
        <code>b.cpp</code>.
    </li>
    <li><b>Propagation of linker flags</b>: Even though
        <code>main.cpp</code> has no knowledge of the implementation of libraries A and B, it still needs to link to its
        direct dependency <code>b.o</code> and the transitive dependencies <code>a.o</code> and <code>libfmt.so</code>.
        The tree of transitive dependencies can become quite unwieldy, and they all need to come together for the final
        linking step.
    </li>
    <li><b>Incremental compilation</b>: Compiling a larger project in its entirety can often take several minutes.
        During development, this can become a serious impediment. We therefore only want to recompile the files that
        actually changed. Since the preprocessor pastes the contents of header files into the source files that include
        them (using simple text substitution of the <code>#include</code> directive), a change in a header file
        can cascade and require many source files to be recompiled. For example, if <code>b.hpp</code> is modified, both
        <code>b.cpp</code> and <code>main.cpp</code> have to be recompiled. For larger projects, the <i>included-by</i>
        graph can grow very complex, as demonstrated by @ref{"ref": "alpaqa-dep"}, and determining these dependencies
        manually is not an option.
    </li>
    <li><b>Portability</b>: The commands above only work for GCC. Users of your project might want to compile it using
        Visual Studio on Windows, or Xcode on macOS, or perhaps even cross-compile it for an embedded system. This would
        require maintaining multiple scripts or build descriptions, with the risk of them getting out of sync.</li>
    <li><b>Lack of integration with IDEs and other tools</b>: IDEs like Visual Studio, VS Code, CLion, Xcode, as well
        as language servers like clangd, or other tools such clang-tidy and Cppcheck won’t be able to easily interact
        with your project if it is described using custom commands or shell scripts.</li>
    <li><b>Implicit assumptions about dependencies</b>: In the example above, we assumed that the <code>{fmt}</code>
        library was installed system-wide, with the necessary files in GCC’s default search paths. However, this is not
        always possible, a user may have dependencies installed in their home folder, in a virtual environment, in a
        subdirectory of the project folder, or somewhere else entirely. Our build script should not make any assumptions
        or hard-code any paths. We need a standardized way to locate third-party libraries and other dependencies that
        works across systems.</li>
    <li><b>Ease of use</b>: By using a custom script or commands to build your project, you make it harder
        for users to get started with your software (especially when things don’t work as expected), and it also
        increases the friction for potential contributors that want to help improve your software or build system.
        There is great value in making the installation of your software as easy as
        <code>cmake -Bbuild -S. && cmake --build build -j && cmake --install build</code>, which is the standard
        procedure for a majority of (newer) C and C++ projects.
    </li>
</ol>

@image{ "file": "images/alpaqa-dep-type-erased-problem.hpp.svg",
"img-attr": {"style": "width: 200%; max-width: 200%"},
"figure-attr": {"style": "max-width: 100%; overflow-x: scroll;"},
"label": "alpaqa-dep",
"caption": "The <i>“included-by”</i> graph of a single header file in a real-world C++ project." }

<p>
    In the next chapter, we’ll look at build systems and build system generators that provide solutions to the
    issues listed above.
</p>

<!-- END -->

<script>
    mermaid.initialize({
        startOnLoad: true,
        theme: 'base',
        themeVariables: {
            primaryColor: '#f4f4ff',
            secondaryColor: '#f0f0f4',
            tertiaryColor: '#FFFCED',
            // fontFamily: 'monospace',
        },
    });
</script>

</html>